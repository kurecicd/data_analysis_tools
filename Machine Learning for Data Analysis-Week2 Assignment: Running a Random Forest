
predictors = data_clean[[‘DISLIKED’,'PARENTS’,'FREQ_M’,'FREQ_M_30D’,'FREQ_C’,'FREQ_C_30D’,'GENDER’]]
#predictors = data_clean[['PARENTS’]]

targets = data_clean.SUSPENSION

pred_train, pred_test, tar_train, tar_test  = train_test_split(predictors, targets, test_size=.4)

pred_train.shape
pred_test.shape
tar_train.shape
tar_test.shape

#Build model on training data
from sklearn.ensemble import RandomForestClassifier

classifier=RandomForestClassifier(n_estimators=25)
classifier=classifier.fit(pred_train,tar_train)

predictions=classifier.predict(pred_test)

sklearn.metrics.confusion_matrix(tar_test,predictions)
sklearn.metrics.accuracy_score(tar_test, predictions)

# fit an Extra Trees model to the data
model = ExtraTreesClassifier()
model.fit(pred_train,tar_train)
# display the relative importance of each attribute
print(model.feature_importances_)

“”“
Running a different number of trees and see the effect
of that on the accuracy of the prediction
”“”

trees=range(25)
accuracy=np.zeros(25)

for idx in range(len(trees)):
  classifier=RandomForestClassifier(n_estimators=idx + 1)
  classifier=classifier.fit(pred_train,tar_train)
  predictions=classifier.predict(pred_test)
  accuracy[idx]=sklearn.metrics.accuracy_score(tar_test, predictions)

plt.cla()
plt.plot(trees, accuracy)

plt.savefig(“temp.png”)
